{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL6RH8poAaGO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojRUHLaZNFre"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from numpy.linalg import inv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " These filters are applied to the input hazy image to obtain two important components: the bright channel and the dark channel. The bright channel represents the maximum intensity value in a local neighborhood, and the dark channel represents the minimum intensity value. These channels help identify the presence of haze in the image.\n"
      ],
      "metadata": {
        "id": "JBgOnu3EN59v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp7d9nlwAfyM"
      },
      "outputs": [],
      "source": [
        "def get_illumination_channel(I, w):\n",
        "    M, N, _ = I.shape\n",
        "    # padding for channels\n",
        "    padded = np.pad(I, ((int(w/2), int(w/2)), (int(w/2), int(w/2)), (0, 0)), 'edge')\n",
        "    darkch = np.zeros((M, N))\n",
        "    brightch = np.zeros((M, N))\n",
        "\n",
        "    for i, j in np.ndindex(darkch.shape):\n",
        "        darkch[i, j] = np.min(padded[i:i + w, j:j + w, :]) # dark channel\n",
        "        brightch[i, j] = np.max(padded[i:i + w, j:j + w, :]) # bright channel\n",
        "\n",
        "    return darkch, brightch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The global atmosphere light is calculated based on the bright channel. It is typically computed as the maximum value in the bright channel and represents the overall illumination in the scene. The atmosphere light is a key parameter used in estimating the transmission of light through the haze.\n"
      ],
      "metadata": {
        "id": "yRipD9_kOBIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvlWAByPAk7U"
      },
      "outputs": [],
      "source": [
        "def get_atmosphere(I, brightch, p=0.1):\n",
        "    M, N = brightch.shape\n",
        "    flatI = I.reshape(M*N, 3) # reshaping image array\n",
        "    flatbright = brightch.ravel() #flattening image array\n",
        "\n",
        "    searchidx = (-flatbright).argsort()[:int(M*N*p)] # sorting and slicing\n",
        "    A = np.mean(flatI.take(searchidx, axis=0), dtype=np.float64, axis=0)\n",
        "    return A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bright channel is used to estimate an initial transmission map. The transmission map is a value between 0 and 1 at each pixel, indicating the fraction of light that has not been scattered or absorbed by the haze. This step provides a rough estimate of how much haze is present in different parts of the image.\n"
      ],
      "metadata": {
        "id": "diz175UpOG2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8lt3uV_At8K"
      },
      "outputs": [],
      "source": [
        "def get_initial_transmission(A, brightch):\n",
        "    A_c = np.max(A)\n",
        "    init_t = (brightch-A_c)/(1.-A_c) # finding initial transmission map\n",
        "    return (init_t - np.min(init_t))/(np.max(init_t) - np.min(init_t))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dark channel is used to correct potentially erroneous transmission estimations from the previous step. Since the dark channel highlights the presence of haze, it can help refine the transmission map by identifying areas that may not have been accurately estimated using the bright channel alone.\n"
      ],
      "metadata": {
        "id": "RRqvNV3mOPU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6nsoVE3AvA3"
      },
      "outputs": [],
      "source": [
        "def get_corrected_transmission(I, A, darkch, brightch, init_t, alpha, omega, w):\n",
        "    im = np.empty(I.shape, I.dtype);\n",
        "    for ind in range(0, 3):\n",
        "        im[:, :, ind] = I[:, :, ind] / A[ind] #divide pixel values by atmospheric light\n",
        "    dark_c, _ = get_illumination_channel(im, w) # dark channel transmission map\n",
        "    dark_t = 1 - omega*dark_c # corrected dark transmission map\n",
        "    corrected_t = init_t # initializing corrected transmission map with initial transmission map\n",
        "    diffch = brightch - darkch # difference between transmission maps\n",
        "\n",
        "    for i in range(diffch.shape[0]):\n",
        "        for j in range(diffch.shape[1]):\n",
        "            if(diffch[i, j] < alpha):\n",
        "                corrected_t[i, j] = dark_t[i, j] * init_t[i, j]\n",
        "\n",
        "    return np.abs(corrected_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The corrected transmission map is further refined using a guided filter. The guided filter is a spatial domain filter that is used to smooth and enhance structures while preserving edges and fine details. It helps in making the transmission map smoother and more visually pleasing.\n",
        "\n"
      ],
      "metadata": {
        "id": "vcJkchK_OYr7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9hAVkJ9NLiG"
      },
      "outputs": [],
      "source": [
        "R, G, B = 0, 1, 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOlBCIQENVkU"
      },
      "outputs": [],
      "source": [
        "def boxfilter(I, r):\n",
        "  M, N = I.shape\n",
        "  dest = np.zeros((M, N))\n",
        "  sumY = np.cumsum(I, axis=0)\n",
        "  dest[:r + 1] = sumY[r:2*r + 1] # top r+1 lines\n",
        "  dest[r + 1:M - r] = sumY[2*r + 1:] - sumY[:M - 2*r - 1]\n",
        "  dest[-r:] = np.tile(sumY[-1], (r, 1)) - sumY[M - 2*r - 1:M - r - 1]\n",
        "  sumX = np.cumsum(dest, axis=1)\n",
        "  dest[:, :r + 1] = sumX[:, r:2*r + 1] # left r+1 columns\n",
        "  dest[:, r + 1:N - r] = sumX[:, 2*r + 1:] - sumX[:, :N - 2*r - 1]\n",
        "  dest[:, -r:] = np.tile(sumX[:, -1][:, None], (1, r)) - sumX[:, N - 2*r - 1:N - r - 1] # right r columns\n",
        "  return dest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W4fuyfHN7Yt"
      },
      "outputs": [],
      "source": [
        "def guided_filter(I, p, r=15, eps=1e-3):\n",
        "  M, N = p.shape\n",
        "  base = boxfilter(np.ones((M, N)), r)\n",
        "  means = [boxfilter(I[:, :, i], r) / base for i in range(3)]\n",
        "  mean_p = boxfilter(p, r) / base\n",
        "  means_IP = [boxfilter(I[:, :, i]*p, r) / base for i in range(3)]\n",
        "  covIP = [means_IP[i] - means[i]*mean_p for i in range(3)]\n",
        "  var = defaultdict(dict)\n",
        "  for i, j in combinations_with_replacement(range(3), 2):\n",
        "      var[i][j] = boxfilter(I[:, :, i]*I[:, :, j], r) / base - means[i]*means[j]\n",
        "  a = np.zeros((M, N, 3))\n",
        "  for y, x in np.ndindex(M, N):\n",
        "    Sigma = np.array([[var[R][R][y, x], var[R][G][y, x], var[R][B][y, x]],\n",
        "                          [var[R][G][y, x], var[G][G][y, x], var[G][B][y, x]],\n",
        "                          [var[R][B][y, x], var[G][B][y, x], var[B][B][y, x]]])\n",
        "    cov = np.array([c[y, x] for c in covIP])\n",
        "    a[y, x] = np.dot(cov, inv(Sigma + eps*np.eye(3)))\n",
        "  b = mean_p - a[:, :, R]*means[R] - a[:, :, G]*means[G] - a[:, :, B]*means[B]\n",
        "  q = (boxfilter(a[:, :, R], r)*I[:, :, R] + boxfilter(a[:, :, G], r)*I[:, :, G] + boxfilter(a[:, :, B], r)*I[:, :, B] + boxfilter(b, r)) / base\n",
        "\n",
        "  return q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the final image"
      ],
      "metadata": {
        "id": "8hLsS_IaOfvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh8S1TSnBDUp"
      },
      "outputs": [],
      "source": [
        "def get_final_image(I, A, refined_t, tmin):\n",
        "    refined_t_broadcasted = np.broadcast_to(refined_t[:, :, None], (refined_t.shape[0], refined_t.shape[1], 3)) # duplicating the channel of 2D refined map to 3 channels\n",
        "    J = (I-A) / (np.where(refined_t_broadcasted < tmin, tmin, refined_t_broadcasted)) + A # finding result\n",
        "\n",
        "    return (J - np.min(J))/(np.max(J) - np.min(J)) # normalized image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Slnz0CgrBQJx"
      },
      "outputs": [],
      "source": [
        "def dehaze(I, tmin=0.1, w=15, alpha=0.4, omega=0.75, p=0.1, eps=1e-3, reduce=False):\n",
        "    I = np.asarray(im, dtype=np.float64) # Convert the input to a float array.\n",
        "    I = I[:, :, :3] / 255\n",
        "    m, n, _ = I.shape\n",
        "    Idark, Ibright = get_illumination_channel(I, w)\n",
        "    A = get_atmosphere(I, Ibright, p)\n",
        "\n",
        "    init_t = get_initial_transmission(A, Ibright)\n",
        "    if reduce:\n",
        "        init_t = reduce_init_t(init_t)\n",
        "    corrected_t = get_corrected_transmission(I, A, Idark, Ibright, init_t, alpha, omega, w)\n",
        "\n",
        "    normI = (I - I.min()) / (I.max() - I.min())\n",
        "    refined_t = guided_filter(normI,corrected_t, w, eps) # applying guided filter\n",
        "    J_refined = get_final_image(I, A, refined_t, tmin)\n",
        "\n",
        "    enhanced = (J_refined*255).astype(np.uint8)\n",
        "    f_enhanced = cv2.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
        "    f_enhanced = cv2.edgePreservingFilter(f_enhanced, flags=1, sigma_s=64, sigma_r=0.2)\n",
        "    return f_enhanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmqwZe-VBUb3"
      },
      "outputs": [],
      "source": [
        "def reduce_init_t(init_t):\n",
        "    init_t = (init_t*255).astype(np.uint8)\n",
        "    xp = [0, 32, 255]\n",
        "    fp = [0, 32, 48]\n",
        "    x = np.arange(256)\n",
        "    table = np.interp(x, xp, fp).astype('uint8')\n",
        "    init_t = cv2.LUT(init_t, table)\n",
        "    init_t = init_t.astype(np.float64)/255\n",
        "    return init_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztJJhNd2CE1g"
      },
      "outputs": [],
      "source": [
        "def reduce_init_t(init_t):\n",
        "    init_t = (init_t*255).astype(np.uint8)\n",
        "    xp = [0, 32, 255]\n",
        "    fp = [0, 32, 48]\n",
        "    x = np.arange(256)\n",
        "    table = np.interp(x, xp, fp).astype('uint8')\n",
        "    init_t = cv2.LUT(init_t, table)\n",
        "    init_t = init_t.astype(np.float64)/255\n",
        "    return init_t\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of code"
      ],
      "metadata": {
        "id": "6kIMwLVDOl2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uykqNEpDbGOe",
        "outputId": "4c7e5bc9-dd17-417f-fb35-dd671219be08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "path=\"/content/drive/MyDrive/53_og.jpg\"\n",
        "im=cv2.imread(path)\n",
        "orig=im.copy\n",
        "tmin = 0.1   # minimum value for t to make J image\n",
        "w = 15       # window size, which determine the corseness of prior images\n",
        "alpha = 0.4  # threshold for transmission correction\n",
        "omega = 0.75 # this is for dark channel prior\n",
        "p = 0.1      # percentage to consider for atmosphere\n",
        "eps = 1e-3   # for J image\n",
        "I = np.asarray(im, dtype=np.float64) # Convert the input to an array.\n",
        "I = I[:, :, :3] / 255\n",
        "f_enhanced2 = dehaze(I, tmin, w, alpha, omega, p, eps, True)\n",
        "details=path.split(\"/\")\n",
        "cv2.imwrite(f\"/content/drive/MyDrive/enhanced_{details[-1]}\", f_enhanced2)\n",
        "  #print(count)\n",
        "  #count+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract('/content/drive/MyDrive/47.jpg')"
      ],
      "metadata": {
        "id": "0C24ciSa7mNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khd42g5OCMjl"
      },
      "outputs": [],
      "source": [
        "im = cv2.imread('/content/drive/MyDrive/Dark(207)/849.jpg')\n",
        "orig = im.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tD4AS53Cpbc"
      },
      "outputs": [],
      "source": [
        "tmin = 0.1   # minimum value for t to make J image\n",
        "w = 15       # window size, which determine the corseness of prior images\n",
        "alpha = 0.4  # threshold for transmission correction\n",
        "omega = 0.75 # this is for dark channel prior\n",
        "p = 0.1      # percentage to consider for atmosphere\n",
        "eps = 1e-3   # for J image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KNZCFeaCvYB"
      },
      "outputs": [],
      "source": [
        "I = np.asarray(im, dtype=np.float64) # Convert the input to an array.\n",
        "I = I[:, :, :3] / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne4bXpGkCz-s"
      },
      "outputs": [],
      "source": [
        "#f_enhanced = dehaze(I, tmin, w, alpha, omega, p, eps)\n",
        "f_enhanced2 = dehaze(I, tmin, w, alpha, omega, p, eps, True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc41DbIoPztJ",
        "outputId": "f47f89a0-a29d-462d-d5c4-72ded53ada1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.imwrite(\"/content/drive/MyDrive/enhanced_image_2.jpg\", f_enhanced2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}